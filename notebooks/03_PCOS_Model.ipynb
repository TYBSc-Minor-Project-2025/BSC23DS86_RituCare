{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCOS Risk Prediction Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook builds a machine learning model to predict Polycystic Ovary Syndrome (PCOS) risk using symptoms, hormonal data, and vitals. We train Logistic Regression (for interpretability) and Random Forest (for accuracy) models, evaluate them, and save the best one for the RituCare app.\n",
    "\n",
    "### Why PCOS Detection Matters\n",
    "PCOS affects 1 in 10 women, causing irregular periods, infertility, and metabolic issues. Early detection via AI can guide users to seek medical advice, improving outcomes.\n",
    "\n",
    "### Features Used\n",
    "- Symptoms: Irregular periods, acne, hirsutism, weight gain.\n",
    "- Hormones: LH, FSH, testosterone, insulin.\n",
    "- Vitals: BMI, blood pressure, cholesterol.\n",
    "\n",
    "**Disclaimer:** This is an AI-assisted screening tool, not a medical diagnosis. Consult a healthcare professional for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visual style\n",
    "sns.set_style(\"whitegrid\")\n",
    "palette = ['#FFB6C1', '#DDA0DD', '#FF69B4', '#FFC0CB', '#E6E6FA']\n",
    "sns.set_palette(palette)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import & Load\n",
    "\n",
    "Load the PCOS dataset and display basic info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../dataset/menstrual_cycle_data.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nHead:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean & Prepare\n",
    "\n",
    "Auto-detect target, clean labels, drop missing targets, remove ID columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target is 'Group' column (0 = normal, 1 = PCOS)\n",
    "target_col = 'Group'\n",
    "print(f\"Target column: {target_col}\")\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target_col])\n",
    "df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "# Remove ID-like columns\n",
    "id_cols = ['ClientID', 'CycleNumber']\n",
    "df = df.drop(columns=id_cols, errors='ignore')\n",
    "\n",
    "# Separate X and y\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "print(f\"After cleaning: {X.shape}, Target classes: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "Split with stratify for balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train classes: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test classes: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Pipeline\n",
    "\n",
    "Numeric: impute median + scale; Categorical: impute mode + one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to numeric where possible\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        try:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Identify column types\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit preprocessor\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed train shape: {X_train_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models to Train\n",
    "\n",
    "Train Logistic Regression and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=400, class_weight='balanced_subsample', random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f\"{name} trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate\n",
    "\n",
    "Compute metrics, confusion matrix, ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = {}\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    results[name] = {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1, 'ROC-AUC': auc}\n",
    "\n",
    "# Display table\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Confusion Matrix for best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['F1'])\n",
    "best_model = trained_models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test_processed)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test_processed)[:, 1])\n",
    "plt.plot(fpr, tpr, color=palette[0], label=f'{best_model_name} (AUC = {results[best_model_name][\"ROC-AUC\"]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pick Best Model\n",
    "\n",
    "Select based on F1, save to pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "print(f\"Best Model: {best_model_name} with F1 {results[best_model_name]['F1']:.3f}\")\n",
    "\n",
    "# Save\n",
    "with open('../models/pcos_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"Model saved to ../models/pcos_model.pkl\")\n",
    "\n",
    "# Also save preprocessor for app\n",
    "with open('../models/preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance\n",
    "\n",
    "Plot for Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if 'Random Forest' in trained_models:\n",
    "    rf = trained_models['Random Forest']\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = list(numeric_features)\n",
    "    importances = rf.feature_importances_\n",
    "    \n",
    "    plt.barh(feature_names[:10], importances[:10], color=palette[1])  # Top 10\n",
    "    plt.title('Top 10 Feature Importance - Random Forest')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    top_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"Top predictive features:\")\n",
    "    for feat, imp in top_features:\n",
    "        print(f\"- {feat}: {imp:.3f}\")\n",
    "    print(\"\\nCycle characteristics and hormonal markers are key predictors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Metrics\n",
    "\n",
    "- **Accuracy**: Overall correct predictions.\n",
    "- **Precision**: True positives over predicted positives.\n",
    "- **Recall**: True positives over actual positives.\n",
    "- **F1**: Balance of precision and recall.\n",
    "- **ROC-AUC**: Ability to distinguish classes.\n",
    "\n",
    "Higher F1 and AUC indicate better performance.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "PCOS model training complete âœ…\n",
    "Best model saved at ../models/pcos_model.pkl\n",
    "\n",
    "Remember, this tool aids in awarenessâ€”always consult a doctor. ðŸŒ¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
